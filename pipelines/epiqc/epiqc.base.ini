[DEFAULT]
# Cluster
cluster_server=abacus.genome.mcgill.ca
cluster_submit_cmd=qsub
cluster_submit_cmd_suffix= | grep "[0-9]"
cluster_walltime=-l walltime=24:00:0
cluster_cpu=-l nodes=1:ppn=1
cluster_other_arg=-m ae -M $JOB_MAIL -W umask=0002
cluster_queue=-q sw
cluster_work_dir_arg=-d
cluster_output_dir_arg=-j oe -o
cluster_job_name_arg=-N
cluster_cmd_produces_job_id=true
cluster_dependency_arg=-W depend=afterok:
cluster_dependency_sep=:
cluster_max_jobs=30000
tmp_dir=${TMPDIR}
portal_output_dir=$PORTAL_OUTPUT_DIR

# Modules
module_ucsc=mugqic/ucsc/v359
module_chromimpute=mugqic/ChromImpute/1.0.3
module_python=mugqic/python/2.7.16
module_java=mugqic/java/openjdk-jdk1.8.0_72

# Ressources
chromsizes=../ressources/hg38_1_23.chrom.sizes
java_other_options=

[bigwiginfo]
low_alert_bases_covered=75000000
medium_alert_bases_covered=25000000

[chromimpute]
ram=50G
chrom=-c chr1
# Put marks for each readset, seperate marks with a comma (eg : H3K4me1, H3K27ac, H3K4me3, H3K4me1). They should be in the same order as in the readset file
marks=H3K27ac,H3K4me1,H3K4me3,H3K9me3,H3K4me1,H3K36me3,H3K27me3,H3K9me3,H3K4me1,H3K36me3,H3K4me3,H3K4me3,H3K9me3,H3K4me1,H3K4me3,H3K4me3,H3K9me3,H3K4me1,H3K27ac,H3K4me3,H3K4me3,H3K27ac,H3K4me1,H3K36me3,H3K36me3,H3K9me3,H3K27me3,H3K36me3,H3K9me3,H3K27me3,H3K9me3,H3K27ac,H3K36me3,H3K9me3,H3K4me3,H3K27me3,H3K27me3,H3K4me3,H3K27me3,H3K9me3,H3K4me1,H3K9me3,H3K27me3,H3K36me3,H3K27me3,H3K36me3,H3K27ac,H3K36me3,H3K4me1,H3K4me1,H3K27ac,H3K36me3,H3K27ac,H3K4me1,H3K4me3,H3K27ac,H3K27me3,H3K27ac,H3K27ac,H3K27me3
# Name of dataset directory that will be created
dataset=dataset
# Name of input info file containing samples marks and filenames that will be created
inputinfofile=chromimpute_inputinfo.txt
# For ChromImpute, chromsize file has to be called hgXsizes_chrN with X being the genome assembly and N the chromosome number
chromsizes=/lb/project/mugqic/projects/rami_test/ressources/hg38sizes_chr1.txt
resolution=-r 25
percent1=1.0
percent2=5.0

[chromimpute_convert]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=24:00:0

[chromimpute_compute_global_dist]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=24:00:0

[chromimpute_generate_train_data]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=72:00:0

[chromimpute_train]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=24:00:0

[chromimpute_apply]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=24:00:0

[chromimpute_eval]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=24:00:0

[signal_noise]
percent1=0.1
percent2=0.05

[epigeec]
# Should be either bw or bg
file_type=bw
resolution=10000
select=
exclude=
# Name of the hdf5 list file that will be created
hdf5_list=hdf5_list.txt

[epigeec_tohdf5]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=24:00:0

[epigeec_correlate]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=24:00:0


