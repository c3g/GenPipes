[DEFAULT]
# Cluster
cluster_server=abacus.genome.mcgill.ca
cluster_submit_cmd=qsub
cluster_submit_cmd_suffix= | grep "[0-9]"
cluster_walltime=-l walltime=24:00:0
cluster_cpu=-l nodes=1:ppn=1
cluster_other_arg=-m ae -M $JOB_MAIL -W umask=0002
cluster_queue=-q sw
cluster_work_dir_arg=-d
cluster_output_dir_arg=-j oe -o
cluster_job_name_arg=-N
cluster_cmd_produces_job_id=true
cluster_dependency_arg=-W depend=afterok:
cluster_dependency_sep=:
cluster_max_jobs=30000
tmp_dir=${TMPDIR}
portal_output_dir=$PORTAL_OUTPUT_DIR

# Modules
module_ucsc=mugqic/ucsc/v359
module_chromimpute=mugqic/ChromImpute/1.0.3
module_python=mugqic/python/2.7.14
module_java=mugqic/java/openjdk-jdk1.8.0_72
module_mugqic_tools=mugqic/mugqic_tools/2.2.4

# Genome
scientific_name=Homo_sapiens
source=UCSC
version=2009-03-08
assembly=hg38
assembly_synonyms=GRCh38
assembly_dir=$MUGQIC_INSTALL_HOME/genomes/species/%(scientific_name)s.%(assembly_synonyms)s
genome_fasta=%(assembly_dir)s/genome/%(scientific_name)s.%(assembly_synonyms)s.fa
genome_dictionary=%(assembly_dir)s/genome/%(scientific_name)s.%(assembly_synonyms)s.dict
genome_bwa_index=%(assembly_dir)s/genome/bwa_index/%(scientific_name)s.%(assembly)s.fa
chromosome_size=%(assembly_dir)s/genome/%(scientific_name)s.%(assembly_synonyms)s.fa.fai
chrominfofile=%(assembly_dir)s/genome/%(scientific_name)s.%(assembly_synonyms)s.fa.tsv


# Ressources
java_other_options=
train_only_user_data=F

[bigwiginfo]
cluster_walltime=-l walltime=15:00

[bigwig_to_bedgraph]
cluster_cpu=-l nodes=1:ppn=2
cluster_walltime=-l walltime=1:00:00

[bigwiginfo]
low_alert_bases_covered=75000000
medium_alert_bases_covered=25000000

[chromimpute]
# Can't be higher than ram allowed to each following chromimpute jobs
ram=10G
# Put marks for each readset, seperate marks with a comma (eg : H3K4me1, H3K27ac, H3K4me3, H3K4me1). They should be in the same order as in the readset file
# Name of dataset directory that will be created
dataset=dataset
# Name of input info file containing samples marks and filenames that will be created
#inputinfofile=chromimpute_inputinfo.txt
resolution=25
percent1=1.0
percent2=5.0

[chromimpute_preprocess]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=15:00
#chromosomes=All
chromosomes=chr1

[chromimpute_convert]
cluster_cpu=-l nodes=1:ppn=2
cluster_walltime=-l walltime=1:00:0
other_options=""

[chromimpute_compute_global_dist]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=3:00:0

[chromimpute_generate_train_data]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=12:00:0
pre_trained_data_path=""

[chromimpute_train]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=12:00:0

[chromimpute_apply]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=12:00:0

[chromimpute_eval]
cluster_cpu=-l nodes=1:ppn=3
cluster_walltime=-l walltime=12:00:0


[signal_noise]
percent1=0.1
percent2=0.05

[epigeec]
# Should be either bw or bg
file_type=bw
resolution=10000
select=
exclude=
# Name of the hdf5 list file that will be created
hdf5_list=hdf5_list.txt

[epigeec_tohdf5]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=24:00:0

[epigeec_correlate]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=24:00:0

[epiqc_report]
chromcount_threshold=23
chromimpute_threshold_M=30
chromimpute_threshold_L=20
signal_noise_thresholdM=0.3
signal_noise_thresholdL=0.2



[epigeec_tohdf5]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=24:00:0

[epigeec_correlate]
cluster_cpu=-l nodes=1:ppn=1
cluster_walltime=-l walltime=24:00:0

[epiqc_report]
chromcount_threshold=23
low_alert_bases_covered=75000000
medium_alert_bases_covered=25000000
chromimpute_threshold_M=30
chromimpute_threshold_L=20
signal_noise_threshold_M=0.3
signal_noise_threshold_L=0.2


